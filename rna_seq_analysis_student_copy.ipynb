{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oqONpOuFcm7"
   },
   "source": [
    "# CSUMB Diagnostics Lab Tool Development\n",
    "\n",
    "YOU and you're team are bioinformaticians for a clinical lab that performs diagnostic testing for the early, and accurate, detection of differentially expressed oncogenes and known oncogenic mutations.\n",
    "\n",
    "Today, you're tasked with developing some software that can automate the quantification of gene expression and the detection of variants from RNA-sequencing data.\n",
    "\n",
    "Case-study data has been deposited in the organizational database: `/media/fileshare/CSUMB_aligned_data/\n",
    "` where you can access it to help you develop these tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0GqzzqxIhSu"
   },
   "source": [
    "## Loading reference sequences (FASTA) into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3S8oirX-E5qe"
   },
   "outputs": [],
   "source": [
    "# this DICTIONARY will hold\n",
    "# genes as KEYS\n",
    "# sequences as VALUES\n",
    "reference_dictionary = {}\n",
    "fasta_path = ''\n",
    "# with the file connection set to our reference FASTA ... \n",
    "with open(fasta_path) as reference:\n",
    "        header = '' # create empty string for headers\n",
    "        sequence = '' # create empty string for sequences\n",
    "\n",
    "        for line in reference:\n",
    "            if line.startswith('>'):\n",
    "                header = line[1:].rstrip()\n",
    "                sequence = ''\n",
    "            else:\n",
    "                sequence += ''.join(line.rstrip().split()).upper()\n",
    "            reference_dictionary[header] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "onsqhdA6IRb8",
    "outputId": "fad2d30d-e611-40d8-c887-1eb21c847125"
   },
   "outputs": [],
   "source": [
    "for gene, sequence in reference_dictionary.items():\n",
    "  print(gene, len(sequence)/1000, 'kb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJzBjAnEIn3y"
   },
   "source": [
    "## Loading Alignments (SAM) into Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBtPhNBTMSiw"
   },
   "source": [
    "The `.sam` alignment files are stored in `/media/fileshare/aligned_data/{KRAS, CDH1, TP53}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uz54q-cKJ-ed",
    "outputId": "4502408d-864b-496d-d903-aea5ed83b0ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: /media/fileshare/CSUMB_aligned_data/*/pair_1: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%ls /media/fileshare/CSUMB_aligned_data/*/pair_1 | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30E6l54ILs7G"
   },
   "source": [
    "We can also use some `bash` commands by pre-pending them with `!`, for example let's look at one of the alignment (.sam) files and think about which lines we need to load and which we need to skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2Hnjpn2LmzX",
    "outputId": "6acdc180-b3f1-4e06-9681-896fcbe18a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: /media/fileshare/CSUMB_aligned_data/KRAS/pair_3/pair_3.sam: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!head /media/fileshare/CSUMB_aligned_data/KRAS/pair_3/pair_3.sam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N61D1u1wUYTB"
   },
   "source": [
    "### And now,\n",
    "\n",
    "Lets write the code.\n",
    "\n",
    "I'm providing the destination object: `alignment_dictionary` that you will populate with `read_id`'s, `read_start` positions, and `read_sequence`'s\n",
    "\n",
    "Use the `FASTA` parser code above as inspiration to implement an approach that reads the `SAM` files line-by-line and stores the relevant information in `alignment_dictionary`\n",
    "\n",
    "hint: not all SAM lines are records. The first few lines of a SAM files are the \"header\". Use the terminal to find a pattern to ignore these lines. Don't include these in your dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "G0YXdc89JUfg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading /Users/vikas/Downloads/CSUMB_aligned_data//KRAS/pair_1/pair_1.sam into aligment dictionary\n"
     ]
    }
   ],
   "source": [
    "alignment_dictionary = {}\n",
    "# keys: read_id\n",
    "# values: tuple(start position of alignment, sequence of aligned read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2kT0OeCMBlU"
   },
   "source": [
    "Explore `alignment_dictionary` by printing its keys. Print the value of the first key thats printed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgCXuWLdZVxr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3rJSYJbPRaN"
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SckegO4NMnpv"
   },
   "source": [
    "## Exercise #1\n",
    "\n",
    "Calculate the number of reads aligned to the reference and the size of your reference gene\n",
    "  - Determine how many reads we have aligned to our reference if possible, compare to the bowtie output and remember that in this special case, we're aligning to only one gene\n",
    "  - store this in the variable \"read_count\"\n",
    "hint:\n",
    "  - we want to measure how many entries are in our alignment obj..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MMwNt1VMm3e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPuSb_SgMzDG"
   },
   "source": [
    "## Exercise #2\n",
    "\n",
    "Calculate the number of reads aligned to the reference per-kilobase length of gene\n",
    "  - Scale / normalize the read abundance to the size of the gene and answer: **why are we doing this**?\n",
    "  \n",
    "\n",
    "hint:\n",
    "  - reuse `read_count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVZjtyr0M4GL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWdDpuC6M4kc"
   },
   "source": [
    "## Exercise #3\n",
    "\n",
    "Calculate per-nucleotide coverage across target gene\n",
    "  - for every position in the reference, determine the number of reads that overlap that position\n",
    "\n",
    "hint:\n",
    "  - Python is 0-based (refer to primer) but the reference sequence is not\n",
    "\n",
    "extra credit:\n",
    "  - using `max(dictionary, key=dictionary.get)` determine the position, and coverage that is the maximum (do the same for `min`) across the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cB4PULWVM9Bq"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgHkPCQiOXi9"
   },
   "source": [
    "## Exercise #4\n",
    "\n",
    "Calculate SNP-aware per-nucleotide coverage of target reference\n",
    "  - for every position in the reference,determine the number of reads that overlap that position with the expected, matching nucleotide as well as the number of reads that contain single-nucleotide polymorphisms (SNPs)\n",
    "\n",
    "hint:\n",
    "  - re-use as much code as possible....\n",
    "\n",
    "extra credit:\n",
    "  - calculate the \"allele frequency\" at positions with\n",
    "  - mutations, where `AF = reference observed / total observations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4lOZPNDO_rd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your dictionary is correct, replace the variable YOUR_DICTIONAR\n",
    "Y_HERE below with your dictionary and a graph should be produced: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "positions_dict = YOUR_DICTIONARY_HERE\n",
    "\n",
    "# Extract the keys and values from positions_dict\n",
    "keys = list(positions_dict.keys())\n",
    "values = list(positions_dict.values())\n",
    "\n",
    "# Create the bar plot\n",
    "plt.bar(keys, values)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Positions')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Bar Plot of positions_dict')\n",
    "\n",
    "\n",
    "# Set y-axis to logarithmic scale\n",
    "plt.yscale('log')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise #5\n",
    "\n",
    "Generalize your approach to work on all of the generated SAM files\n",
    "  * Create two functions: \n",
    "    * 1) Read each SAM file into an alignment dictionary. Store the dictionary in another dictionary where the key is the sample name, and the value is the alignment dictionary\n",
    "    * 2) Process the SAM file to do the following:\n",
    "  * For each file and its corresponding reference, print the position with the highest Allele fraction in the following format: \n",
    "      * \"Pair 1/2/3 from gene A had an allele fraction of B for gene C at position D\"\n",
    "      \n",
    "hint: you can modify the following if statement to check if a file exists: \n",
    "* if os.path.exists(file_path):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
