{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CSUMB Diagnostics Lab Tool Development\n",
        "\n",
        "YOU and you're team are bioinformaticians for a clinical lab that performs diagnostic testing for the early, and accurate, detection of differentially expressed oncogenes and known oncogenic mutations.\n",
        "\n",
        "Today, you're tasked with developing some software that can automate the quantification of gene expression and the detection of variants from RNA-sequencing data.\n",
        "\n",
        "Case-study data has been deposited in the organizational database: `drive/Shareddrives/CSUMB-GREAT` where you can access it to help you develop these tools."
      ],
      "metadata": {
        "id": "4oqONpOuFcm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First things first:\n",
        "\n",
        "**MOUNT DRIVE IN LEFT PANEL!!**\n",
        "\n",
        "We need to navigate to the directory that stores all our data\n",
        "\n",
        "The `%` line is used by google colab to execute \"magic\" functions -- in this case, we just want to re-locate to the CSUMB-GREAT directory in `Shareddrives`"
      ],
      "metadata": {
        "id": "pnozWX9gFvHp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YIelJw5SD7nt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f589f326-dbfe-4563-ae53-356273041976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/CSUMB-GREAT'\n",
            "/content/drive/MyDrive/CSUMB-GREAT\n"
          ]
        }
      ],
      "source": [
        "# for me, since I own the drive, I use this path\n",
        "%cd drive/MyDrive/CSUMB-GREAT\n",
        "# for you, since its shared, use:\n",
        "# %cd drive/Shareddrives/CSUMB-GREAT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`%pwd` will confirm our location"
      ],
      "metadata": {
        "id": "0tdjlib8GxKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "id": "6yQ1gmUlGvZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading reference sequences (FASTA) into Python"
      ],
      "metadata": {
        "id": "C0GqzzqxIhSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this DICTIONARY will hold\n",
        "# genes as KEYS\n",
        "# sequences as VALUES\n",
        "reference_dictionary = {}\n",
        "\n",
        "# with the file connection set to our reference FASTA ... \n",
        "with open(\"data/reference/three_gene_ref.fa\") as reference:\n",
        "        header = '' # create empty string for headers\n",
        "        sequence = '' # create empty string for sequences\n",
        "\n",
        "        for line in reference:\n",
        "            if line.startswith('>'):\n",
        "                header = line[1:].rstrip()\n",
        "                sequence = ''\n",
        "            else:\n",
        "                sequence += ''.join(line.rstrip().split()).upper()\n",
        "            reference_dictionary[header] = sequence"
      ],
      "metadata": {
        "id": "3S8oirX-E5qe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for gene, sequence in reference_dictionary.items():\n",
        "  print(gene, len(sequence)/1000, 'kb')"
      ],
      "metadata": {
        "id": "onsqhdA6IRb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad2d30d-e611-40d8-c887-1eb21c847125"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CDH1 4.811 kb\n",
            "KRAS 5.43 kb\n",
            "TP53 2.512 kb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Alignments (SAM) into Python"
      ],
      "metadata": {
        "id": "bJzBjAnEIn3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `.sam` alignment files are stored in `data/aligned_data/{KRAS, CDH1, TP53}`"
      ],
      "metadata": {
        "id": "jBtPhNBTMSiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%ls data/aligned_data/*/pair_1 | head"
      ],
      "metadata": {
        "id": "Uz54q-cKJ-ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4502408d-864b-496d-d903-aea5ed83b0ab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/aligned_data/CDH1/pair_1:\n",
            "pair_1.sam\n",
            "\n",
            "data/aligned_data/KRAS/pair_1:\n",
            "pair_1.sam\n",
            "\n",
            "data/aligned_data/TP53/pair_1:\n",
            "pair_1.sam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use some `bash` commands by pre-pending them with `!`, for example let's look at one of the alignment (.sam) files and think about which lines we need to load and which we need to skip"
      ],
      "metadata": {
        "id": "30E6l54ILs7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head data/aligned_data/KRAS/pair_3/pair_3.sam"
      ],
      "metadata": {
        "id": "W2Hnjpn2LmzX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6acdc180-b3f1-4e06-9681-896fcbe18a70"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@HD\tVN:1.5\tSO:unsorted\tGO:query\n",
            "@SQ\tSN:CDH1\tLN:4811\n",
            "@SQ\tSN:KRAS\tLN:5430\n",
            "@SQ\tSN:TP53\tLN:2512\n",
            "@PG\tID:bowtie2\tPN:bowtie2\tVN:2.5.1\tCL:\"./bowtie2-2.5.1-linux-x86_64/bowtie2-align-s -x bowtie_index/ -1 input_data/KRAS/pair_3/g12c_50_R1.fastq.header_modified_R1.fastq -2 input_data/KRAS/pair_3/g12c_50_R2.fastq.header_modified_R2.fastq -S aligned_data/KRAS/pair_3/pair_3.sam --no-unal\"\n",
            "511677\t65\tKRAS\t130\t42\t75M\t=\t2026\t1971\tAAGGCGGCGGCGGGGCCAGAGGCTCAGCGGCTCCCAGGTGCGGGAGAGAGGCCTGCTGAAAATGACTGAATATAA\t@GID@CD>><DF<FH=@@I>BHAB?<H=@>HAEEH=>DB>GD?EGG<@BH==EBFD<ECEB@DIC><??IDGEGF\tAS:i:0\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:75\tYS:i:0\tYT:Z:DP\n",
            "511677\t129\tKRAS\t2026\t42\t75M\t=\t130\t-1971\tACTCTGTGGTGGTCCTGCTGACAAATCAAGAGCATTGCTTTTGTTTCTTAAGAAAACAAACTCTTTTTTAAAAAT\t@GID@CD>><DF<FH=@@I>BHAB?<H=@>HAEEH=>DB>GD?EGG<@BH==EBFD<ECEB@DIC><??IDGEGF\tAS:i:0\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:75\tYS:i:0\tYT:Z:DP\n",
            "540285\t65\tKRAS\t2139\t42\t75M\t=\t3208\t1144\tTGGTGGTGTGCCAAGACATTAATTTTTTTTTTAAACAATGAAGTGAAAAAGTTTTACAATCTCTAGGTTTGGCTA\tCEGAG??EDGE=AA<@ID<DF=@?D=<HC@?IH?DHEE>BCI>E@?DBG=IBDAE@HHA?H=G<=GGHBD?IBEA\tAS:i:0\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:75\tYS:i:0\tYT:Z:DP\n",
            "540285\t129\tKRAS\t3208\t42\t75M\t=\t2139\t-1144\tCATCTCAGCTCACTGCAACCTCCATCTCCCAGGTTCAAGCGATTCTCGTGCCTCGGCCTCCTGAGTAGCTGGGAT\tCEGAG??EDGE=AA<@ID<DF=@?D=<HC@?IH?DHEE>BCI>E@?DBG=IBDAE@HHA?H=G<=GGHBD?IBEA\tAS:i:0\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:75\tYS:i:0\tYT:Z:DP\n",
            "937457\t65\tKRAS\t1739\t42\t75M\t=\t1236\t-578\tAGACTGCTCTTTCATAGTATAACTTTAAATCTTTTCTTCAACTTGAGTCTTTGAAGATAGTTTTAATTCTGCTTG\tG=HC=BB>>AAGHE?B?@H@=D<<EH@>G?<CBIHI=H>EE>A<=?B=CAHGHADE>>@I<DHGIA<GFA<E?@H\tAS:i:0\tXN:i:0\tXM:i:0\tXO:i:0\tXG:i:0\tNM:i:0\tMD:Z:75\tYS:i:0\tYT:Z:DP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### And now,\n",
        "\n",
        "Lets write the code.\n",
        "\n",
        "I'm providing the destination object: `alignment_dictionary` that you will populate with `read_id`'s, `read_start` positions, and `read_sequence`'s\n",
        "\n",
        "Use the `FASTA` parser code above as inspiration to implement an approach that reads the `SAM` files line-by-line and stores the relevant information in `alignment_dictionary`"
      ],
      "metadata": {
        "id": "N61D1u1wUYTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alignment_dictionary = {}\n",
        "# keys: read_id\n",
        "# values: tuple(start position of alignment, sequence of aligned read)\n",
        "\n",
        "# define an object to hold the name of the SAM file you want to load\n",
        "pre_path = 'data/aligned_data' # this part of the path is constant; all .sams are here\n",
        "\n",
        "gene = 'KRAS' # gene is defined as you need it\n",
        "#gene = 'TP53'\n",
        "#gene = 'CDH1'\n",
        "\n",
        "pair = 'pair_3' # pair is defined as you need it\n",
        "\n",
        "# then, we stitch all of these strings together with `+` and creat a full path\n",
        "input_sam = pre_path + '/' + gene + '/' + pair + '/' + pair + \".sam\" # pick one .sam for now...\n",
        "# ex. data/aligned_data/KRAS/pair_3/pair_3.sam\n",
        "\n",
        "print('loading ' + input_sam + ' into aligment dictionary')\n",
        "\n",
        "# start here, test and try things, populate the dictionary\n",
        "with open(input_sam) as alignment:\n",
        "        for line in alignment:\n",
        "          print(line)\n"
      ],
      "metadata": {
        "id": "G0YXdc89JUfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore `alignment_dictionary` by printing its keys and values"
      ],
      "metadata": {
        "id": "a2kT0OeCMBlU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fgCXuWLdZVxr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises"
      ],
      "metadata": {
        "id": "o3rJSYJbPRaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise #1\n",
        "\n",
        "Calculate the number of reads aligned to the reference and the size of your reference gene\n",
        "  - Determine how many reads we have aligned to our reference if possible, compare to the bowtie output and remember that in this special case, we're aligning to only one gene\n",
        "  \n",
        "hint:\n",
        "  - we want to measure how many entries are in our alignment obj..."
      ],
      "metadata": {
        "id": "SckegO4NMnpv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_MMwNt1VMm3e"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise #2\n",
        "\n",
        "Calculate the number of reads aligned to the reference per-kilobase length of gene\n",
        "  - Scale / normalize the read abundance to the size of the gene and answer: **why are we doing this**?\n",
        "  \n",
        "\n",
        "hint:\n",
        "  - reuse `read_count`"
      ],
      "metadata": {
        "id": "HPuSb_SgMzDG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OVZjtyr0M4GL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise #3\n",
        "\n",
        "Calculate per-nucleotide coverage across target gene\n",
        "  - for every position in the reference, determine the number of reads that overlap that position\n",
        "\n",
        "hint:\n",
        "  - Python is 0-based (refer to primer) but the reference sequence is not\n",
        "  - with that said, you have reads and their start positions **on the reference**, you need to convert the read position to the reference position using this information ..... \n",
        "\n",
        "extra credit:\n",
        "  - using `max(dictionary, key=dictionary.get)` determine the position, and coverage that is the maximum (do the same for `min`) across the reference"
      ],
      "metadata": {
        "id": "nWdDpuC6M4kc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cB4PULWVM9Bq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise #4\n",
        "\n",
        "Calculate SNP-aware per-nucleotide coverage of target reference\n",
        "  - for every position in the reference,determine the number of reads that overlap that position with the expected, matching nucleotide as well as the number of reads that contain single-nucleotide polymorphisms (SNPs)\n",
        "\n",
        "hint:\n",
        "  - re-use as much code as possible....\n",
        "\n",
        "extra credit:\n",
        "  - calculate the \"allele frequency\" at positions with\n",
        "  - mutations, where `AF = reference observed / total observations`"
      ],
      "metadata": {
        "id": "QgHkPCQiOXi9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o4lOZPNDO_rd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Advanced) Exercise #5:\n",
        "\n",
        "Calculate SNP-aware per-nucleotide coverage of target reference\n",
        "using the `MD:Z` tag in the SAM file, use this to calculate\n",
        "Allele Frequency\n",
        "  - you must create this *without* using the previous objects created to enable the other variant calling approach"
      ],
      "metadata": {
        "id": "X7XalxhOTMMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1\n",
        "\n",
        "Parse your `.sam` file of choice for the MD:Z tag column\n",
        "\n",
        "hint:\n",
        "  - start with the code you deployed for SAM parsing [above](https://colab.research.google.com/drive/1Cp-BX7JXC-n_BDiVP3IB1RhVIhTjf084#scrollTo=G0YXdc89JUfg&line=13&uniqifier=1)"
      ],
      "metadata": {
        "id": "dN6MUsHzTTGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "md_dictionary = {}\n",
        "# keys: read_id\n",
        "# values: tuple(start position of alignment, MD tag)"
      ],
      "metadata": {
        "id": "p4RVjy1ETvd2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2\n",
        "\n",
        "Implement the scanning and calculation\n",
        "\n",
        "hint:\n",
        "  - you need the same information as you did before..."
      ],
      "metadata": {
        "id": "nYtjPBKQTvyn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lYuHXAbIT7E6"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}